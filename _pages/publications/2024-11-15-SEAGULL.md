
<div class='paper-box'>
<div class='paper-box-image-text'>
<div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='images/publications/SEAGULL.png' alt="sym" width="100%"></div></div>

<div class='paper-box-text' markdown="1">
<div style="margin-bottom: 5px; font-size:1.2em">
    <b>SEAGULL: No-reference Image Quality Assessment for Regions of Interest via Vision-Language Instruction Tuning </b>
</div>

**Zewen Chen**, Juan Wang, Wen Wang, Sunhan Xu, et al.

<b style="color:rgb(140, 27, 19)"> TL;DR: </b> We propose a novel network (SEAGULL) and construct two datasets (SEAGULL-100w and SEAGULL-3k) to achieve fine-grained IQA for any ROIs.

<div style="margin-top: 5px;">
    <a href="https://arxiv.org/abs/2411.10161"><img src="https://img.shields.io/badge/Arxiv-red" style="max-width: 100%; height: auto;"></a>
    <a href="https://github.com/chencn2020/SEAGULL"><img src="https://img.shields.io/badge/GitHub-181717?style=flat&logo=github
    " style="max-width: 100%; height: auto;"></a>
    <a href="https://huggingface.co/spaces/Zevin2023/SEAGULL"><img src="https://huggingface.co/datasets/huggingface/badges/raw/main/open-in-hf-spaces-sm-dark.svg" alt="Open in Spaces" style="max-width: 100%; height: auto;"></a>
    <a href="https://huggingface.co/datasets/Zevin2023/SEAGULL-100w"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-SEAGULL--100w-green" style="max-width: 100%; height: auto;"></a>
    <a href="https://huggingface.co/datasets/Zevin2023/SEAGULL-3k"><img src="https://img.shields.io/badge/SEAGULL--3k-green" style="max-width: 100%; height: auto;"></a>
</div>

</div>
</div> 
<details>
    <summary><b>Quick Read (Click Me)</b></summary> Existing Image Quality Assessment (IQA) methods achieve remarkable success in analyzing quality for overall image, but few works explore quality analysis for Regions of Interest (ROIs). The quality analysis of ROIs can provide fine-grained guidance for image quality improvement and is crucial for scenarios focusing on region-level quality. This paper proposes a novel network, SEAGULL, which can <b>SE</b>e and <b>A</b>ssess ROIs quality with <b>GU</b>idance from a <b>L</b>arge vision-<b>L</b>anguage model. SEAGULL incorporates a vision-language model (VLM), masks generated by Segment Anything Model (SAM) to specify ROIs, and a meticulously designed Mask-based Feature Extractor (MFE) to extract global and local tokens for specified ROIs, enabling accurate fine-grained IQA for ROIs. Moreover, this paper constructs two ROI-based IQA datasets, SEAGULL-100w and SEAGULL-3k, for training and evaluating ROI-based IQA. SEAGULL-100w comprises about 100w synthetic distortion images with 33 million ROIs for pre-training to improve the model's ability of regional quality perception, and SEAGULL-3k contains about 3k authentic distortion ROIs to enhance the model's ability to perceive real world distortions. After pre-training on SEAGULL-100w and fine-tuning on SEAGULL-3k, SEAGULL shows remarkable performance on fine-grained ROI quality assessment.
</details>
</div>
