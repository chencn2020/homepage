---
title: "SEAGULL: No-reference Image Quality Assessment for Regions of Interest via Vision-Language Instruction Tuning"
collection: publications
date: 2024-07-01
venue: 'Arxiv'
citation: '<b>Chen Z</b>, Qin H, Wang J, et al. Promptiqa: Boosting the performance and generalization for no-reference image quality assessment via prompts[C]//European Conference on Computer Vision. Springer, Cham, 2025: 247-264.'
codeurl: 'https://github.com/chencn2020/SEAGULL'
onlineDemo: 'https://huggingface.co/spaces/Zevin2023/SEAGULL'
paperdate: 03/2024
paperYear: 2024
framework: 'https://chencn2020.github.io/images/paper/SEAGULL.png'
fast_read: 'Due to the diversity of assessment requirements in various application scenarios for the IQA task, existing IQA methods struggle to directly adapt to these varied requirements after training. Thus, when facing new requirements, a typical approach is fine-tuning these models on datasets specifically created for those requirements. However, it is time-consuming to establish IQA datasets. In this work, we propose a Prompt-based IQA (PromptIQA) that can directly adapt to new requirements without fine-tuning after training. On one hand, it utilizes a short sequence of Image-Score Pairs (ISP) as prompts for targeted predictions, which significantly reduces the dependency on the data requirements. On the other hand, PromptIQA is trained on a mixed dataset with two proposed data augmentation strategies to learn diverse requirements, thus enabling it to effectively adapt to new requirements. Experiments indicate that the PromptIQA outperforms SOTA methods with higher performance and better generalization.'
arxiv: "https://arxiv.org/abs/2403.04993"
---
